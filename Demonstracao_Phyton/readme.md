# k-NN Classifier com Scikit-learn

Uma aplicaÃ§Ã£o interativa para demonstraÃ§Ã£o e experimentaÃ§Ã£o com o algoritmo k-Nearest Neighbors (k-NN) usando Python, Tkinter e Scikit-learn.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa uma interface grÃ¡fica completa para classificaÃ§Ã£o usando o algoritmo k-NN, permitindo visualizar em tempo real como diferentes parÃ¢metros afetam o desempenho do classificador. A aplicaÃ§Ã£o utiliza um dataset de exemplo com frutas (MaÃ§Ã£ e Banana) baseado em caracterÃ­sticas como doÃ§ura e textura.

## âœ¨ Funcionalidades

### ğŸ¯ ClassificaÃ§Ã£o Interativa
- **PrediÃ§Ã£o em tempo real**: Arraste os sliders para ver a classificaÃ§Ã£o instantÃ¢nea
- **VisualizaÃ§Ã£o grÃ¡fica**: GrÃ¡fico de dispersÃ£o com regiÃµes de decisÃ£o
- **Destaque de vizinhos**: VisualizaÃ§Ã£o dos k-vizinhos mais prÃ³ximos

### ğŸ”§ ParÃ¢metros ConfigurÃ¡veis
- **Valor de k**: NÃºmero de vizinhos (1-15)
- **Algoritmo**: auto, ball_tree, kd_tree, brute
- **MÃ©trica de distÃ¢ncia**: euclidean, manhattan, minkowski, chebyshev
- **NormalizaÃ§Ã£o**: OpÃ§Ã£o para normalizar os dados

### ğŸ“Š MÃ©tricas e AnÃ¡lises
- **AcurÃ¡cia do modelo**
- **Cross-validation** (5-fold)
- **RelatÃ³rio de classificaÃ§Ã£o** completo
- **Probabilidades** de cada classe
- **Tabela de vizinhos** mais prÃ³ximos

### ğŸ¨ Interface AvanÃ§ada
- **Design profissional** com cores organizadas
- **Abas organizadas** para diferentes funcionalidades
- **VisualizaÃ§Ãµes dinÃ¢micas** com matplotlib
- **InformaÃ§Ãµes tÃ©cnicas** detalhadas

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
```bash
Python 3.7+
```

### DependÃªncias
```bash
pip install tkinter matplotlib numpy scikit-learn pandas seaborn
```

### InstalaÃ§Ã£o das dependÃªncias
```bash
# Usando pip
pip install -r requirements.txt

# Ou instalar individualmente
pip install matplotlib numpy scikit-learn pandas seaborn
```

## ğŸ“¦ Estrutura do Projeto

```
knn-classifier/
â”‚
â”œâ”€â”€ knn_classifier.py          # Arquivo principal
â”œâ”€â”€ README.md                  # Este arquivo
â”œâ”€â”€ requirements.txt           # DependÃªncias
â””â”€â”€ screenshots/              # Capturas de tela (opcional)
```

## ğŸ® Como Usar

### 1. Executar a aplicaÃ§Ã£o
```bash
python knn_classifier.py
```

### 2. Interface Principal
A aplicaÃ§Ã£o possui trÃªs abas principais:

#### **ParÃ¢metros BÃ¡sicos**
- **DoÃ§ura**: Ajusta a caracterÃ­stica doÃ§ura (0-10)
- **Textura**: Ajusta a caracterÃ­stica textura (0-12)
- **Valor de k**: Define o nÃºmero de vizinhos

#### **ConfiguraÃ§Ãµes AvanÃ§adas**
- **Algoritmo**: Escolha o algoritmo de busca
- **MÃ©trica**: Selecione a mÃ©trica de distÃ¢ncia
- **NormalizaÃ§Ã£o**: Ative/desative a normalizaÃ§Ã£o dos dados
- **Retreinar Modelo**: Aplica as novas configuraÃ§Ãµes
- **Mostrar RelatÃ³rio**: Exibe mÃ©tricas detalhadas

#### **Resultados**
- **Vizinhos Mais PrÃ³ximos**: Tabela com os vizinhos encontrados
- **Probabilidades**: Probabilidades de cada classe
- **InformaÃ§Ãµes TÃ©cnicas**: Detalhes da configuraÃ§Ã£o atual

### 3. InterpretaÃ§Ã£o dos Resultados

#### GrÃ¡fico Principal
- **Pontos coloridos**: Dataset de treinamento
- **Estrela**: Ponto a ser classificado
- **CÃ­rculos pretos**: k-vizinhos mais prÃ³ximos
- **Fundo colorido**: RegiÃµes de decisÃ£o

#### MÃ©tricas
- **AcurÃ¡cia**: Percentual de acertos no dataset
- **Cross-Validation**: ValidaÃ§Ã£o cruzada com 5 folds
- **RelatÃ³rio**: Precision, Recall e F1-Score por classe

## ğŸ”¬ Algoritmos DisponÃ­veis

### Algoritmos de Busca
- **auto**: Escolha automÃ¡tica baseada nos dados
- **ball_tree**: Eficiente para dados de alta dimensÃ£o
- **kd_tree**: RÃ¡pido para baixa dimensÃ£o
- **brute**: ForÃ§a bruta (sempre funciona)

### MÃ©tricas de DistÃ¢ncia
- **euclidean**: DistÃ¢ncia euclidiana clÃ¡ssica
- **manhattan**: DistÃ¢ncia de Manhattan (L1)
- **minkowski**: GeneralizaÃ§Ã£o das anteriores
- **chebyshev**: DistÃ¢ncia de Chebyshev (Lâˆ)

## ğŸ“Š Dataset

O dataset inclui 18 pontos com duas caracterÃ­sticas:
- **DoÃ§ura** (0-10): NÃ­vel de doÃ§ura da fruta
- **Textura** (0-12): Textura da superfÃ­cie

**Classes:**
- ğŸŒ **Banana**: Pontos amarelos
- ğŸ **MaÃ§Ã£**: Pontos vermelhos

## ğŸ¯ Casos de Uso

### ğŸ“ Educacional
- Ensino de algoritmos de Machine Learning
- DemonstraÃ§Ã£o de conceitos k-NN
- VisualizaÃ§Ã£o de hiperparÃ¢metros

### ğŸ”¬ Pesquisa
- Prototipagem rÃ¡pida de classificadores
- Teste de diferentes configuraÃ§Ãµes
- AnÃ¡lise de sensibilidade de parÃ¢metros

### ğŸ’¼ Profissional
- Baseline para projetos de classificaÃ§Ã£o
- DemonstraÃ§Ã£o para stakeholders
- ValidaÃ§Ã£o de conceitos

## ğŸ› ï¸ PersonalizaÃ§Ã£o

### Modificar o Dataset
```python
# Em __init__
self.dados_completos = np.array([
    # Seus dados aqui
])

self.classes_completas = [
    # Suas classes aqui
]
```

### Adicionar Novas MÃ©tricas
```python
# Em setup_ui, adicionar Ã  lista de mÃ©tricas
values=['euclidean', 'manhattan', 'minkowski', 'chebyshev', 'sua_metrica']
```

### Personalizar Cores
```python
# Em __init__
self.cores = {
    'Classe1': '#cor1',
    'Classe2': '#cor2'
}
```

## ğŸ“ˆ MÃ©tricas Explicadas

### **AcurÃ¡cia**
Percentual de classificaÃ§Ãµes corretas sobre o total.

### **Cross-Validation**
ValidaÃ§Ã£o cruzada com 5 folds para estimar a performance real.

### **Precision**
ProporÃ§Ã£o de prediÃ§Ãµes positivas corretas.

### **Recall**
ProporÃ§Ã£o de casos positivos identificados corretamente.

### **F1-Score**
MÃ©dia harmÃ´nica entre Precision e Recall.

## ğŸ› Troubleshooting

### Erro de ImportaÃ§Ã£o
```bash
# Instalar dependÃªncias faltantes
pip install matplotlib numpy scikit-learn pandas seaborn
```

### Tkinter nÃ£o encontrado
```bash
# Ubuntu/Debian
sudo apt-get install python3-tk

# CentOS/RHEL
sudo yum install tkinter
```

### Problemas de Performance
- Reduza o nÃºmero de pontos no dataset
- Use algoritmo 'ball_tree' para dados maiores
- Desative a plotagem da regiÃ£o de decisÃ£o

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¥ Autores

- **Desenvolvimento**: DemonstraÃ§Ã£o acadÃªmica de Machine Learning
- **InspiraÃ§Ã£o**: Algoritmo k-NN clÃ¡ssico da literatura

## ğŸ™ Agradecimentos

- Scikit-learn pela excelente biblioteca de ML
- Matplotlib pela visualizaÃ§Ã£o de dados
- Tkinter pela interface grÃ¡fica

## ğŸ“š ReferÃªncias

- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [k-NN Algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
- [Python Machine Learning](https://www.python.org/)

---

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**
